{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Domain Knowledge\n",
                "\n",
                "This dataset represents **hourly POS (Point of Sale) checkout counts** for a retail or e-commerce operation.\n",
                "\n",
                "Each CSV contains:\n",
                "- **time**: The hour of the day (00h to 23h).\n",
                "- **today**: Number of completed checkouts during that hour on the current day.\n",
                "- **yesterday**: Number of completed checkouts during the same hour on the previous day.\n",
                "- **same_day_last_week**: Checkouts during the same hour, on the same weekday, one week ago.\n",
                "- **avg_last_week**: Average hourly checkouts over the past 7 days for the same hour.\n",
                "- **avg_last_month**: Average hourly checkouts over the past 30 days for the same hour.\n",
                "\n",
                "The purpose of this data is to allow **real-time comparison of today's sales performance against historical baselines**. This is a common pattern in operational monitoring dashboards (e.g., Grafana, CloudWatch) where operators compare live metrics to prior periods to quickly spot deviations.\n",
                "\n",
                "Typical anomaly patterns to watch for:\n",
                "- **Sudden drops to zero**: Could indicate a system outage (payment gateway failure, server crash, deployment gone wrong).\n",
                "- **Unexpected spikes**: Could indicate a flash sale, bot activity, or double-counting bug.\n",
                "- **Gradual drift from averages**: Could indicate a slow degradation, changing user behavior, or data pipeline lag.\n",
                "\n",
                "We have two snapshots:\n",
                "- `checkout_1.csv`: A snapshot taken at the end of a presumably normal day.\n",
                "- `checkout_2.csv`: A snapshot taken at the end of a day that may contain an anomalous event."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.patches as mpatches\n",
                "import numpy as np\n",
                "import sqlite3\n",
                "\n",
                "plt.rcParams['figure.figsize'] = (15, 6)\n",
                "plt.rcParams['font.size'] = 12"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Loading\n",
                "\n",
                "Loading both checkout snapshots."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Checkout 1: 24 rows, 6 columns\n",
                        "Checkout 2: 24 rows, 6 columns\n",
                        "\n",
                        "Columns: ['time', 'today', 'yesterday', 'same_day_last_week', 'avg_last_week', 'avg_last_month']\n"
                    ]
                }
            ],
            "source": [
                "df_c1 = pd.read_csv('sample_data/checkout/checkout_1.csv')\n",
                "df_c2 = pd.read_csv('sample_data/checkout/checkout_2.csv')\n",
                "\n",
                "print(f\"Checkout 1: {df_c1.shape[0]} rows, {df_c1.shape[1]} columns\")\n",
                "print(f\"Checkout 2: {df_c2.shape[0]} rows, {df_c2.shape[1]} columns\")\n",
                "print(f\"\\nColumns: {list(df_c1.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 Sanity Checks - Checkout 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CHECKOUT 1 SANITY CHECKS\n",
                        "========================================\n",
                        "Shape: (24, 6)\n",
                        "\n",
                        "Null Values:\n",
                        "time                  0\n",
                        "today                 0\n",
                        "yesterday             0\n",
                        "same_day_last_week    0\n",
                        "avg_last_week         0\n",
                        "avg_last_month        0\n",
                        "dtype: int64\n",
                        "\n",
                        "Data Types:\n",
                        "time                      str\n",
                        "today                   int64\n",
                        "yesterday               int64\n",
                        "same_day_last_week      int64\n",
                        "avg_last_week         float64\n",
                        "avg_last_month        float64\n",
                        "dtype: object\n",
                        "\n",
                        "Expected 24 hourly rows: PASS\n",
                        "Duplicate time entries: 0\n",
                        "Negative values in 'today': 0\n",
                        "Negative values in 'yesterday': 0\n",
                        "Negative values in 'same_day_last_week': 0\n",
                        "Negative values in 'avg_last_week': 0\n",
                        "Negative values in 'avg_last_month': 0\n"
                    ]
                }
            ],
            "source": [
                "print(\"CHECKOUT 1 SANITY CHECKS\")\n",
                "print(\"=\" * 40)\n",
                "print(f\"Shape: {df_c1.shape}\")\n",
                "print(f\"\\nNull Values:\\n{df_c1.isnull().sum()}\")\n",
                "print(f\"\\nData Types:\\n{df_c1.dtypes}\")\n",
                "print(f\"\\nExpected 24 hourly rows: {'PASS' if df_c1.shape[0] == 24 else 'FAIL'}\")\n",
                "print(f\"Duplicate time entries: {df_c1['time'].duplicated().sum()}\")\n",
                "print(f\"Negative values in 'today': {(df_c1['today'] < 0).sum()}\")\n",
                "print(f\"Negative values in 'yesterday': {(df_c1['yesterday'] < 0).sum()}\")\n",
                "print(f\"Negative values in 'same_day_last_week': {(df_c1['same_day_last_week'] < 0).sum()}\")\n",
                "print(f\"Negative values in 'avg_last_week': {(df_c1['avg_last_week'] < 0).sum()}\")\n",
                "print(f\"Negative values in 'avg_last_month': {(df_c1['avg_last_month'] < 0).sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Sanity Checks - Checkout 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CHECKOUT 2 SANITY CHECKS\n",
                        "========================================\n",
                        "Shape: (24, 6)\n",
                        "\n",
                        "Null Values:\n",
                        "time                  0\n",
                        "today                 0\n",
                        "yesterday             0\n",
                        "same_day_last_week    0\n",
                        "avg_last_week         0\n",
                        "avg_last_month        0\n",
                        "dtype: int64\n",
                        "\n",
                        "Data Types:\n",
                        "time                      str\n",
                        "today                   int64\n",
                        "yesterday               int64\n",
                        "same_day_last_week      int64\n",
                        "avg_last_week         float64\n",
                        "avg_last_month        float64\n",
                        "dtype: object\n",
                        "\n",
                        "Expected 24 hourly rows: PASS\n",
                        "Duplicate time entries: 0\n",
                        "Negative values in 'today': 0\n",
                        "Negative values in 'yesterday': 0\n",
                        "Negative values in 'same_day_last_week': 0\n",
                        "Negative values in 'avg_last_week': 0\n",
                        "Negative values in 'avg_last_month': 0\n"
                    ]
                }
            ],
            "source": [
                "print(\"CHECKOUT 2 SANITY CHECKS\")\n",
                "print(\"=\" * 40)\n",
                "print(f\"Shape: {df_c2.shape}\")\n",
                "print(f\"\\nNull Values:\\n{df_c2.isnull().sum()}\")\n",
                "print(f\"\\nData Types:\\n{df_c2.dtypes}\")\n",
                "print(f\"\\nExpected 24 hourly rows: {'PASS' if df_c2.shape[0] == 24 else 'FAIL'}\")\n",
                "print(f\"Duplicate time entries: {df_c2['time'].duplicated().sum()}\")\n",
                "print(f\"Negative values in 'today': {(df_c2['today'] < 0).sum()}\")\n",
                "print(f\"Negative values in 'yesterday': {(df_c2['yesterday'] < 0).sum()}\")\n",
                "print(f\"Negative values in 'same_day_last_week': {(df_c2['same_day_last_week'] < 0).sum()}\")\n",
                "print(f\"Negative values in 'avg_last_week': {(df_c2['avg_last_week'] < 0).sum()}\")\n",
                "print(f\"Negative values in 'avg_last_month': {(df_c2['avg_last_month'] < 0).sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Cross-Validation Between Snapshots"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CROSS-VALIDATION\n",
                        "========================================\n",
                        "Same columns: PASS\n",
                        "Same time entries: PASS\n",
                        "\n",
                        "Checkout 1 - Total Today: 526\n",
                        "Checkout 2 - Total Today: 427\n",
                        "\n",
                        "Checkout 1 'yesterday' should match Checkout 2 'today' if consecutive days:\n",
                        "  Result: NO MATCH\n",
                        "\n",
                        "Checkout 2 'yesterday' should match Checkout 1 'today' if consecutive days:\n",
                        "  Result: MATCH\n",
                        "\n",
                        "CONCLUSION: Checkout 2 was captured the day AFTER Checkout 1.\n",
                        "Checkout 2's 'yesterday' column matches Checkout 1's 'today' column perfectly.\n"
                    ]
                }
            ],
            "source": [
                "print(\"CROSS-VALIDATION\")\n",
                "print(\"=\" * 40)\n",
                "print(f\"Same columns: {'PASS' if list(df_c1.columns) == list(df_c2.columns) else 'FAIL'}\")\n",
                "print(f\"Same time entries: {'PASS' if list(df_c1['time']) == list(df_c2['time']) else 'FAIL'}\")\n",
                "\n",
                "print(f\"\\nCheckout 1 - Total Today: {df_c1['today'].sum()}\")\n",
                "print(f\"Checkout 2 - Total Today: {df_c2['today'].sum()}\")\n",
                "\n",
                "print(f\"\\nCheckout 1 'yesterday' should match Checkout 2 'today' if consecutive days:\")\n",
                "match = (df_c1['yesterday'] == df_c2['today']).all()\n",
                "print(f\"  Result: {'MATCH' if match else 'NO MATCH'}\")\n",
                "\n",
                "print(f\"\\nCheckout 2 'yesterday' should match Checkout 1 'today' if consecutive days:\")\n",
                "match2 = (df_c2['yesterday'] == df_c1['today']).all()\n",
                "print(f\"  Result: {'MATCH' if match2 else 'NO MATCH'}\")\n",
                "\n",
                "print(f\"\\nCONCLUSION: Checkout 2 was captured the day AFTER Checkout 1.\")\n",
                "print(f\"Checkout 2's 'yesterday' column matches Checkout 1's 'today' column perfectly.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.4 Consistency Check: Today vs Historical Baselines"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_deviation(df, label):\n",
                "    df = df.copy()\n",
                "    df['hour'] = df['time'].str.replace('h', '').astype(int)\n",
                "    df['dev_vs_yesterday'] = df['today'] - df['yesterday']\n",
                "    df['dev_vs_last_week'] = df['today'] - df['same_day_last_week']\n",
                "    df['dev_vs_avg_week'] = df['today'] - df['avg_last_week']\n",
                "    df['dev_vs_avg_month'] = df['today'] - df['avg_last_month']\n",
                "\n",
                "    df['pct_dev_avg_week'] = np.where(\n",
                "        df['avg_last_week'] > 0,\n",
                "        ((df['today'] - df['avg_last_week']) / df['avg_last_week']) * 100,\n",
                "        0\n",
                "    )\n",
                "\n",
                "    print(f\"\\n{label} - Deviation Summary (Today vs Baselines)\")\n",
                "    print(\"=\" * 60)\n",
                "\n",
                "    business_hours = df[(df['hour'] >= 8) & (df['hour'] <= 22)]\n",
                "\n",
                "    print(f\"\\nBusiness Hours (08h-22h):\")\n",
                "    print(f\"  Total Today:           {business_hours['today'].sum()}\")\n",
                "    print(f\"  Total Yesterday:       {business_hours['yesterday'].sum()}\")\n",
                "    print(f\"  Total Same Day LW:     {business_hours['same_day_last_week'].sum()}\")\n",
                "    print(f\"  Sum Avg Last Week:     {business_hours['avg_last_week'].sum():.1f}\")\n",
                "    print(f\"  Sum Avg Last Month:    {business_hours['avg_last_month'].sum():.1f}\")\n",
                "\n",
                "    zero_hours_today = df[df['today'] == 0]\n",
                "    if len(zero_hours_today) > 0:\n",
                "        zero_during_business = zero_hours_today[(zero_hours_today['hour'] >= 8) & (zero_hours_today['hour'] <= 22)]\n",
                "        if len(zero_during_business) > 0:\n",
                "            print(f\"\\n  ALERT: Zero sales during business hours at: {list(zero_during_business['time'])}\")\n",
                "            for _, row in zero_during_business.iterrows():\n",
                "                print(f\"    {row['time']}: today=0, yesterday={row['yesterday']}, \"\n",
                "                      f\"avg_week={row['avg_last_week']}, avg_month={row['avg_last_month']}\")\n",
                "        else:\n",
                "            print(f\"\\n  Zero sales only during off-peak hours: {list(zero_hours_today['time'])}\")\n",
                "\n",
                "    large_drops = business_hours[business_hours['pct_dev_avg_week'] < -50]\n",
                "    if len(large_drops) > 0:\n",
                "        print(f\"\\n  ALERT: Hours with >50% drop vs weekly average:\")\n",
                "        for _, row in large_drops.iterrows():\n",
                "            print(f\"    {row['time']}: today={row['today']}, avg_week={row['avg_last_week']}, \"\n",
                "                  f\"deviation={row['pct_dev_avg_week']:.1f}%\")\n",
                "\n",
                "    return df\n",
                "\n",
                "df_c1_dev = compute_deviation(df_c1, \"CHECKOUT 1\")\n",
                "df_c2_dev = compute_deviation(df_c2, \"CHECKOUT 2\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. SQL Query - Anomaly Detection\n",
                "\n",
                "Using an in-memory SQLite database to simulate querying the checkout data for anomalies.\n",
                "The query identifies hours where today's sales deviate significantly from the weekly average during business hours."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "conn = sqlite3.connect(':memory:')\n",
                "\n",
                "df_c1_dev.to_sql('checkout_1', conn, index=False, if_exists='replace')\n",
                "df_c2_dev.to_sql('checkout_2', conn, index=False, if_exists='replace')\n",
                "\n",
                "query = \"\"\"\n",
                "SELECT\n",
                "    'checkout_1' AS snapshot,\n",
                "    time,\n",
                "    hour,\n",
                "    today,\n",
                "    yesterday,\n",
                "    same_day_last_week,\n",
                "    avg_last_week,\n",
                "    avg_last_month,\n",
                "    ROUND(today - avg_last_week, 2) AS abs_deviation,\n",
                "    CASE\n",
                "        WHEN avg_last_week > 0 THEN ROUND(((today - avg_last_week) / avg_last_week) * 100, 1)\n",
                "        ELSE 0\n",
                "    END AS pct_deviation\n",
                "FROM checkout_1\n",
                "WHERE hour BETWEEN 8 AND 22\n",
                "  AND (\n",
                "      (avg_last_week > 0 AND ABS((today - avg_last_week) / avg_last_week) > 0.5)\n",
                "      OR (today = 0 AND avg_last_week > 1)\n",
                "  )\n",
                "\n",
                "UNION ALL\n",
                "\n",
                "SELECT\n",
                "    'checkout_2' AS snapshot,\n",
                "    time,\n",
                "    hour,\n",
                "    today,\n",
                "    yesterday,\n",
                "    same_day_last_week,\n",
                "    avg_last_week,\n",
                "    avg_last_month,\n",
                "    ROUND(today - avg_last_week, 2) AS abs_deviation,\n",
                "    CASE\n",
                "        WHEN avg_last_week > 0 THEN ROUND(((today - avg_last_week) / avg_last_week) * 100, 1)\n",
                "        ELSE 0\n",
                "    END AS pct_deviation\n",
                "FROM checkout_2\n",
                "WHERE hour BETWEEN 8 AND 22\n",
                "  AND (\n",
                "      (avg_last_week > 0 AND ABS((today - avg_last_week) / avg_last_week) > 0.5)\n",
                "      OR (today = 0 AND avg_last_week > 1)\n",
                "  )\n",
                "ORDER BY snapshot, hour\n",
                "\"\"\"\n",
                "\n",
                "df_anomalies = pd.read_sql_query(query, conn)\n",
                "conn.close()\n",
                "\n",
                "print(\"SQL QUERY RESULTS - Anomalous Hours (>50% deviation or zero sales during business hours)\")\n",
                "print(\"=\" * 100)\n",
                "print(df_anomalies.to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualization"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1 Checkout 1 - Normal Day"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 1, figsize=(16, 12), sharex=True)\n",
                "\n",
                "hours = df_c1_dev['hour']\n",
                "\n",
                "axes[0].plot(hours, df_c1_dev['today'], 'o-', color='#2196F3', linewidth=2.5, markersize=6, label='Today')\n",
                "axes[0].plot(hours, df_c1_dev['yesterday'], 's--', color='#FF9800', linewidth=1.5, markersize=4, label='Yesterday')\n",
                "axes[0].plot(hours, df_c1_dev['same_day_last_week'], '^--', color='#4CAF50', linewidth=1.5, markersize=4, label='Same Day Last Week')\n",
                "axes[0].fill_between(hours, df_c1_dev['avg_last_week'], alpha=0.15, color='#9C27B0', label='Avg Last Week')\n",
                "axes[0].fill_between(hours, df_c1_dev['avg_last_month'], alpha=0.1, color='#607D8B', label='Avg Last Month')\n",
                "axes[0].set_title('Checkout 1 (Normal Day) - Hourly Sales Comparison', fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylabel('Number of Checkouts')\n",
                "axes[0].legend(loc='upper left', fontsize=9)\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "axes[0].axvspan(8, 22, alpha=0.05, color='green', label='Business Hours')\n",
                "\n",
                "hours2 = df_c2_dev['hour']\n",
                "\n",
                "axes[1].plot(hours2, df_c2_dev['today'], 'o-', color='#F44336', linewidth=2.5, markersize=6, label='Today')\n",
                "axes[1].plot(hours2, df_c2_dev['yesterday'], 's--', color='#FF9800', linewidth=1.5, markersize=4, label='Yesterday')\n",
                "axes[1].plot(hours2, df_c2_dev['same_day_last_week'], '^--', color='#4CAF50', linewidth=1.5, markersize=4, label='Same Day Last Week')\n",
                "axes[1].fill_between(hours2, df_c2_dev['avg_last_week'], alpha=0.15, color='#9C27B0', label='Avg Last Week')\n",
                "axes[1].fill_between(hours2, df_c2_dev['avg_last_month'], alpha=0.1, color='#607D8B', label='Avg Last Month')\n",
                "\n",
                "anomaly_mask = (df_c2_dev['today'] == 0) & (df_c2_dev['hour'] >= 8) & (df_c2_dev['hour'] <= 22)\n",
                "if anomaly_mask.any():\n",
                "    anomaly_hours = df_c2_dev[anomaly_mask]\n",
                "    axes[1].scatter(anomaly_hours['hour'], anomaly_hours['today'], color='red', s=200, zorder=5,\n",
                "                   marker='X', edgecolors='darkred', linewidths=2, label='ANOMALY (0 sales)')\n",
                "    for _, row in anomaly_hours.iterrows():\n",
                "        axes[1].annotate(f\"OUTAGE\\n{row['time']}\",\n",
                "                         xy=(row['hour'], 0),\n",
                "                         xytext=(row['hour'], row['avg_last_week'] + 5),\n",
                "                         fontsize=8, fontweight='bold', color='red', ha='center',\n",
                "                         arrowprops=dict(arrowstyle='->', color='red', lw=1.5))\n",
                "\n",
                "axes[1].set_title('Checkout 2 (Anomalous Day) - Hourly Sales Comparison', fontsize=14, fontweight='bold')\n",
                "axes[1].set_ylabel('Number of Checkouts')\n",
                "axes[1].set_xlabel('Hour of Day')\n",
                "axes[1].legend(loc='upper left', fontsize=9)\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "axes[1].axvspan(8, 22, alpha=0.05, color='green')\n",
                "axes[1].set_xticks(range(24))\n",
                "axes[1].set_xticklabels([f\"{h:02d}h\" for h in range(24)], rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('checkout_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 Revenue Impact Estimation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "outage_hours = df_c2_dev[(df_c2_dev['today'] == 0) & (df_c2_dev['hour'] >= 8) & (df_c2_dev['hour'] <= 22)]\n",
                "\n",
                "print(\"ESTIMATED IMPACT OF THE OUTAGE\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "expected_from_yesterday = outage_hours['yesterday'].sum()\n",
                "expected_from_last_week = outage_hours['same_day_last_week'].sum()\n",
                "expected_from_avg_week = outage_hours['avg_last_week'].sum()\n",
                "expected_from_avg_month = outage_hours['avg_last_month'].sum()\n",
                "\n",
                "print(f\"\\nOutage window: {list(outage_hours['time'].values)}\")\n",
                "print(f\"Duration: {len(outage_hours)} hours\")\n",
                "print(f\"\\nExpected sales (based on different baselines):\")\n",
                "print(f\"  Yesterday:          {expected_from_yesterday} checkouts\")\n",
                "print(f\"  Same day last week: {expected_from_last_week} checkouts\")\n",
                "print(f\"  Avg last week:      {expected_from_avg_week:.1f} checkouts\")\n",
                "print(f\"  Avg last month:     {expected_from_avg_month:.2f} checkouts\")\n",
                "\n",
                "total_today_c2 = df_c2_dev['today'].sum()\n",
                "total_without_outage = total_today_c2 + expected_from_avg_week\n",
                "\n",
                "print(f\"\\nActual total sales (Checkout 2 day): {total_today_c2}\")\n",
                "print(f\"Estimated total without outage:      {total_without_outage:.0f}\")\n",
                "print(f\"Lost checkouts (est.):               {expected_from_avg_week:.0f}\")\n",
                "print(f\"Revenue impact:                      {(expected_from_avg_week / total_without_outage * 100):.1f}% of daily sales\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.3 Deviation Heatmap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
                "\n",
                "for idx, (df_dev, label, ax) in enumerate([\n",
                "    (df_c1_dev, 'Checkout 1 (Normal)', axes[0]),\n",
                "    (df_c2_dev, 'Checkout 2 (Anomalous)', axes[1])\n",
                "]):\n",
                "    deviations = df_dev[['dev_vs_yesterday', 'dev_vs_last_week', 'dev_vs_avg_week', 'dev_vs_avg_month']].T\n",
                "    deviations.columns = df_dev['time']\n",
                "    deviations.index = ['vs Yesterday', 'vs Last Week', 'vs Avg Week', 'vs Avg Month']\n",
                "\n",
                "    vmax = max(abs(deviations.values.min()), abs(deviations.values.max()))\n",
                "    im = ax.imshow(deviations.values, cmap='RdYlGn', aspect='auto', vmin=-vmax, vmax=vmax)\n",
                "\n",
                "    ax.set_xticks(range(len(deviations.columns)))\n",
                "    ax.set_xticklabels(deviations.columns, rotation=90, fontsize=8)\n",
                "    ax.set_yticks(range(len(deviations.index)))\n",
                "    ax.set_yticklabels(deviations.index, fontsize=9)\n",
                "    ax.set_title(label, fontsize=12, fontweight='bold')\n",
                "\n",
                "    plt.colorbar(im, ax=ax, shrink=0.8, label='Deviation (count)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('checkout_deviation_heatmap.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Conclusions\n",
                "\n",
                "### Data Consistency\n",
                "- Both datasets have 24 rows (one per hour), no null values, no duplicate time entries, and no negative counts.\n",
                "- The `yesterday` column in Checkout 2 matches the `today` column in Checkout 1, confirming they are consecutive days.\n",
                "\n",
                "### Anomaly Detected in Checkout 2\n",
                "- **Checkout 2 shows zero sales at 15h, 16h, and 17h** — three consecutive hours during peak business time.\n",
                "- This is highly anomalous because:\n",
                "  - Yesterday (Checkout 1) had 51, 41, and 45 sales at those same hours.\n",
                "  - The weekly average for those hours is ~22, ~22, and ~18.\n",
                "  - The monthly average for those hours is ~28, ~26, and ~23.\n",
                "- **The pattern is consistent with a system outage** (e.g., payment gateway went down, checkout service crashed, or a bad deployment).\n",
                "\n",
                "### Evidence Supporting an Outage\n",
                "1. Sales **abruptly drop to exactly zero** — not a gradual decline, which rules out seasonal behavior.\n",
                "2. The drop is **during the highest-traffic hours** of the day, where averages are at their peak.\n",
                "3. Sales **resume at 18h** (13 checkouts), suggesting the system was restored, though at a reduced rate — possibly a recovery phase.\n",
                "4. The **14h hour already shows a drop** (19 vs 32 yesterday, vs 35 same day LW) — the outage may have started during 14h.\n",
                "5. Checkout 1 (the previous day) shows **no such anomaly**, confirming this is not a recurring pattern.\n",
                "\n",
                "### Estimated Impact\n",
                "- Approximately **62 lost checkouts** during the outage window (based on weekly average).\n",
                "- This represents a significant percentage of the day's total sales."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "cw_test",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
